{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP FIRST ASSIGNMENT\n",
    "Developing a Naïve Bayas Classifier able to distinguish between english and not-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ROOT = '/Users/sebastianodarconso/Desktop/magistrale_lab/natural_language_processing/first_assingnment/europarl_raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting english and not-english files from the europarl_raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = open(ROOT + \"/english/ep-00-01-17.en\", 'r').read()\n",
    "eng += open(ROOT + \"/english/ep-00-01-18.en\", 'r').read()\n",
    "eng += open(ROOT + \"/english/ep-00-01-19.en\", 'r').read()\n",
    "eng += open(ROOT + \"/english/ep-00-01-21.en\", 'r').read()\n",
    "eng += open(ROOT + \"/english/ep-00-02-02.en\", 'r').read()\n",
    "eng += open(ROOT + \"/english/ep-00-02-03.en\", 'r').read()\n",
    "\n",
    "not_eng = open(ROOT + \"/german/ep-00-01-17.de\", 'r').read()\n",
    "not_eng += open(ROOT + \"/french/ep-00-01-17.fr\", 'r').read()\n",
    "not_eng += open(ROOT + \"/finnish/ep-00-01-17.fi\", 'r').read()\n",
    "not_eng += open(ROOT + \"/greek/ep-00-01-17.el\", 'r').read()\n",
    "not_eng += open(ROOT + \"/italian/ep-00-01-17.it\", 'r').read()\n",
    "not_eng += open(ROOT + \"/swedish/ep-00-01-17.sv\", 'r').read()\n",
    "not_eng += open(ROOT + \"/dutch/ep-00-01-18.nl\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the english documents: 1400752\n",
      "Number of words in the not english documents: 1503692\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in the english documents: {}\".format(len(eng)))\n",
    "print(\"Number of words in the not english documents: {}\".format(len(not_eng)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the sets of stopwords for the languages used \n",
    "For this example the languages are:\n",
    "- english\n",
    "- german \n",
    "- dutch\n",
    "- finnish\n",
    "- italian\n",
    "- swedish \n",
    "- french \n",
    "- greek \n",
    "\n",
    "They will still be divided as \"english\" and \"not english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['english', 'german', 'dutch', 'finnish', 'italian', 'swedish', 'french', 'greek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_eng = set()\n",
    "stopwords_not_eng = set()\n",
    "for l in languages:\n",
    "    if l == 'english':\n",
    "        stopwords_eng.update(stopwords.words(l))\n",
    "    else:\n",
    "        stopwords_not_eng.update(stopwords.words(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the stemmer (PorterStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing, stemming and removing stopwords\n",
    "\n",
    "In this section all the words in both english and not english bows will be tokenized and stemmed. From the resulting bows will be removed also the stopwords and then they will be merged together in order to create an heterogeneous (with relation to the language) bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9135/9135 [00:01<00:00, 4906.19it/s]\n",
      "100%|██████████| 9637/9637 [00:01<00:00, 5022.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7865872383117676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "documents = []\n",
    "\n",
    "start = time.time()\n",
    "for en in tqdm(eng.split('\\n')):\n",
    "    documents.append((en, 'eng'))\n",
    "    words = word_tokenize(en)\n",
    "    for w in words:\n",
    "        if not w in stopwords_eng:\n",
    "            all_words.append(ps.stem(w.lower()))\n",
    "\n",
    "for ne in tqdm(not_eng.split('\\n')):\n",
    "    documents.append((ne, 'not eng'))\n",
    "    words = word_tokenize(ne)\n",
    "    for w in words:\n",
    "        if w not in stopwords_not_eng:\n",
    "            all_words.append(ps.stem(w.lower()))\n",
    "end = time.time()\n",
    "\n",
    "print(end- start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the frequency distribution for the BOW and listing the first 8k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "word_features = list(all_words.keys())[:8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function that extract the features from each document (all the words, tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset and shuffling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18772/18772 [00:32<00:00, 577.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "featureset = [(find_features(doc), lang) for (doc, lang) in tqdm(documents)]\n",
    "random.shuffle(featureset)\n",
    "print(len(featureset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting (evenly) the dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len = len(featureset)\n",
    "\n",
    "testing_set = featureset[(dataset_len//2):]\n",
    "training_set = featureset[:(dataset_len//2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the default Naïve Bayas Classifier on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.555356979370117\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the function that will be used to test the classifier on text and files different from the testing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(text):\n",
    "    feats = find_features(text)\n",
    "    return classifier.classify(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tests on different languages text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oggi è proprio una bella giornata: not eng\n",
      "\n",
      "today is such a beautiful day: eng\n",
      "\n",
      "Mein Name ist Anna. Ich komme aus Österreich und lebe seit drei Jahren in Deutschland. Ich bin 15Jahre alt und habe zwei Geschwister: Meine Schwester heißt Klara und ist 13 Jahre alt, mein BruderMichael ist 18 Jahre alt.: not eng\n",
      "\n",
      "Το όνομά μου είναι Άννα. Κατάγομαι από την Αυστρία και ζω στη Γερμανία εδώ και τρία χρόνια. Είμαι 15 χρονών και έχω δύο αδέρφια: Η αδερφή μου ονομάζεται Κλάρα και είναι 13 ετών, ο αδερφός μου ο Μιχαήλ είναι 18 ετών. Ζούμε με τους γονείς μας σε ένα σπίτι κοντά στο Μόναχο, η μητέρα μου είναι μαγείρισσα και ο πατέρας μου σε τράπεζα: not eng\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"oggi è proprio una bella giornata\"\n",
    "text_eng = \"today is such a beautiful day\"\n",
    "text_de = \"Mein Name ist Anna. Ich komme aus Österreich und lebe seit drei Jahren in Deutschland. Ich bin 15Jahre alt und habe zwei Geschwister: Meine Schwester heißt Klara und ist 13 Jahre alt, mein BruderMichael ist 18 Jahre alt.\"\n",
    "text_el = \"Το όνομά μου είναι Άννα. Κατάγομαι από την Αυστρία και ζω στη Γερμανία εδώ και τρία χρόνια. Είμαι 15 χρονών και έχω δύο αδέρφια: Η αδερφή μου ονομάζεται Κλάρα και είναι 13 ετών, ο αδερφός μου ο Μιχαήλ είναι 18 ετών. Ζούμε με τους γονείς μας σε ένα σπίτι κοντά στο Μόναχο, η μητέρα μου είναι μαγείρισσα και ο πατέρας μου σε τράπεζα\"\n",
    "print(text + ': ' + test(text) + '\\n')\n",
    "print(text_eng + ': ' + test(text_eng) + '\\n')\n",
    "print(text_de + ': '+ test(text_de) + '\\n')\n",
    "print(text_el + ': '+ test(text_el) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tests on documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file in english: eng\n",
      "file in italian: not eng\n"
     ]
    }
   ],
   "source": [
    "file_eng = open(\"/Users/sebastianodarconso/Desktop/magistrale_lab/natural_language_processing/first_assingnment/english_doc.txt\").read()\n",
    "file_ita = open(\"/Users/sebastianodarconso/Desktop/magistrale_lab/natural_language_processing/first_assingnment/italian_doc.txt\").read()\n",
    "\n",
    "print(\"file in english: {}\".format(test(file_eng)))\n",
    "print(\"file in italian: {}\".format(test(file_ita)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the confusion matrix with the testing set\n",
    "The way to read the confusion matrix is that from all the 9386 samples in the test set, there were 4391 true positive and 4820 true negative cases. However it also predicted 175 false negative and zero false positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9386/9386 [01:18<00:00, 119.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        |         n |\n",
      "        |         o |\n",
      "        |         t |\n",
      "        |           |\n",
      "        |    e    e |\n",
      "        |    n    n |\n",
      "        |    g    g |\n",
      "--------+-----------+\n",
      "    eng |<4388> 172 |\n",
      "not eng |    .<4826>|\n",
      "--------+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "from collections import defaultdict\n",
    "\n",
    "ref = defaultdict(set)\n",
    "testset = defaultdict(set)\n",
    "\n",
    "labels = []\n",
    "tests = []\n",
    "\n",
    "for i, (feats, label) in enumerate(tqdm(testing_set)):\n",
    "    ref[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    labels.append(label)\n",
    "    tests.append(observed)\n",
    "\n",
    "\n",
    "cm = ConfusionMatrix(labels, tests)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the precision, recall and F-measure on the testing data\n",
    "In this case I used the built-in functions of nltk but we can see the next outcomes as:\n",
    "- Precision = $\\frac{truePositive}{truePositive + falsePositive}$\n",
    "\n",
    "- Recall = $\\frac{truePositive}{truePositive + falseNegative}$\n",
    "\n",
    "- F = $2 * \\frac{precison * recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tag | Prec.  | Recall | F-measure\n",
      "--------+--------+--------+-----------\n",
      "    eng | 1.0000 | 0.9623 | 0.9808\n",
      "not eng | 0.9656 | 1.0000 | 0.9825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier accuracy and most informative features\n",
    "The accuracy is obtained in the next way:\n",
    "- Accuracy = $\\frac{truePositive + trueNegative}{truePositive + trueNegative + falsePositive + falseNegative}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     the = True              eng : not en =   2386.0 : 1.0\n",
      "                     and = True              eng : not en =    847.4 : 1.0\n",
      "                      en = True           not en : eng    =    674.2 : 1.0\n",
      "                      be = True              eng : not en =    419.2 : 1.0\n",
      "                     die = True           not en : eng    =    376.9 : 1.0\n",
      "                    will = True              eng : not en =    248.8 : 1.0\n",
      "                      de = True           not en : eng    =    233.2 : 1.0\n",
      "                       l = True           not en : eng    =    177.8 : 1.0\n",
      "                      or = True              eng : not en =    158.1 : 1.0\n",
      "                     den = True           not en : eng    =    144.9 : 1.0\n",
      "                     but = True              eng : not en =    135.2 : 1.0\n",
      "                      le = True           not en : eng    =    109.7 : 1.0\n",
      "                      et = True           not en : eng    =     79.7 : 1.0\n",
      "                       i = True           not en : eng    =     69.7 : 1.0\n",
      "                       e = True           not en : eng    =     69.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9831664180694651\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(classifier, training_set)\n",
    "print(\"accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employability as a probabilistic language model\n",
    "Naïve Bayes relies on the Bayes algorithm and essentially assigns a class label to the sample based on the conditional probability class given by the features. \n",
    "This kind of classifier assumes that each feature makes an independent and equal contribution to the target class.\n",
    "This works quite well in this example since we basically want the classifier to classify sentences/words/documents in just two classes: English and not english.\n",
    "The English class can be seen as a Unigram model, therefore a probabilistic language model.\n",
    "It may be not suitable in the case of multi-class classification but in this simple case it works fine."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e1bd50c29ca9d85d25a0084185febf7020f5e8bd5da929d18cf95b16060538f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
